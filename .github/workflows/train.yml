name: Train Model

on:
  push:
    branches:
      - main
      # force training for now
      # paths:
      #   - 'model_train.py'

jobs:
  train-evaluate:
    runs-on: self-hosted
    env:
      DATASET_EXISTS: ''

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      # PT 1
      # check if dataset exists (predefined directory) and download depending on this
      # After making sure we have the data, Launch tensorflow GPU container
      # i.e. node.run("docker run -d --rm -p 8888:8888 --gpus all quay.io/jupyter/tensorflow-notebook:cuda-tensorflow-2.16.1") make this non-notebook
      # something like this tensorflow/tensorflow:2.16.1-gpu --> need to pass dataset from paraserver to -v argument into container --> -v /path/on/host:/path/in/container
      # Immediately run a command on the container (inside the container on the server) --> docker run --> commands inside the container

      - name: Check and Download Dataset in Docker Container
        run: |
          docker run --rm --gpus all \
            -v "$(pwd):/workspace" \
            tensorflow/tensorflow:latest-gpu /bin/bash"
              echo 'Connected to Docker Container';
              echo 'Current Directory:'; pwd;
              echo 'Listing files:'; ls -la /workspace;
              if [ -d 'content/Food-11' ]; then
                echo 'Dataset already exists. Skipping download.';
                echo 'DATASET_EXISTS=true' >> /tmp/github_env;
              else
                echo 'Dataset does not exist. Will download it.';
                echo 'DATASET_EXISTS=false' >> /tmp/github_env;
                mkdir -p content/Food-11;
                apt-get update && \
                apt-get install -y gdown unzip && \
                gdown https://drive.google.com/uc?id=1dt3CD3ICdLbTf80sNJ25TPBDKu_qyCnq -O content/Food-11/dataset.zip && \
                unzip content/Food-11/dataset.zip -d content/Food-11;
              fi
            "

      # WE DO NOT NEED TO BE REINSTALLING ALL OF THIS HERE - ALL in container (tf should include anyways)

      # OLD STUFF
      # - name: Set up Python
      #   uses: actions/setup-python@v4
      #   with:
      #     python-version: '3.8'

      # - name: Install Dependencies
      #   run: |
      #     python -m pip install --upgrade pip
      #     pip install -r requirements.txt

      # - name: Download dataset
      #   run: |
      #     mkdir -p content/Food-11
      #     gdown https://drive.google.com/uc?id=1dt3CD3ICdLbTf80sNJ25TPBDKu_qyCnq -O content/Food-11/dataset.zip
      #     unzip content/Food-11/dataset.zip -d content/Food-11
      #   working-directory: .
      # END OF OLD STUFF

      # # TRAIN MODEL IN CONTAINER
      # - name: Run Training Script
      #   # Make sure these are run inside the container (can use docker exec --> specify container name)
      #   run: |
      #     python model_train.py

      # - name: Display Evaluation Results
      #   run: |
      #     cat evaluation_metrics.txt || echo "Evaluation metrics not available"

      # - name: Parse Evaluation Metrics
      #   id: metrics
      #   run: |
      #     evaluation_accuracy=$(grep 'evaluation_accuracy' evaluation_metrics.txt | cut -d' ' -f2)
      #     echo "::set-output name=evaluation_accuracy::$evaluation_accuracy"
      #   continue-on-error: true

      # - name: Display Evaluation Accuracy
      #   run: |
      #     echo "Evaluation Accuracy is: ${{ steps.metrics.outputs.evaluation_accuracy }}"

      # - name: Redeploy if Accuracy Meets Threshold
      # # made it 0.2 for now to check workflow
      #   if: steps.metrics.outputs.evaluation_accuracy && steps.metrics.outputs.evaluation_accuracy >= 0.2
      #   run: |
      #     git config --local user.email "tin2294@gmail.com"
      #     git config --local user.name "Ting Ting"
      #     git tag -fa "redeploy" -m "Auto-redeploy from training workflow"
      #     git push origin redeploy
