name: Continuous X Workflow

on:
  push:
    branches:
      - main
    paths:
        - 'model_train.py'
    #     - 'utils.py'
jobs:
  train:
    runs-on: gpu-p100
    env:
      DATASET_EXISTS: ''

    steps:
      - name: Manage Dataset Volume and Download
        id: manage_dataset
        run: |
          docker run -d --rm --name training_container \
            -v food11_data:/tmp/content/Food-11 \
            -v saved_models:/tmp/temp_models \
            -w /workspace \
            tensorflow/tensorflow:latest-gpu tail -f /dev/null

            docker exec training_container bash -c "
            apt-get update && apt-get install -y git;
            if [ -d 'workspace/src/image-classification-continuous-x' ]; then
              echo 'Repository already exists. Updating...';
              cd /workspace/image-classification-continuous-x && git pull origin main;
            else
              echo 'Cloning repository...';
              git clone https://github.com/tin2294/image-classification-continuous-x.git workspace/src/image-classification-continuous-x;
            fi
          "

          if docker exec training_container bash -c "[ -d '/tmp/content/Food-11' ] && [ \"\$(ls -A /tmp/content/Food-11)\" ]"; then
            echo "Volume 'food11_data' already contains data. Skipping download."
          else
            echo "Volume 'food11_data' is empty. Downloading dataset."

            docker exec training_container bash -c "
              set -e;
              echo 'Downloading and setting up dataset...';
              mkdir -p /tmp/content/Food-11 && \
              apt-get update && \
              pip3 install gdown && \
              gdown https://drive.google.com/uc?id=1dt3CD3ICdLbTf80sNJ25TPBDKu_qyCnq -O /tmp/content/Food-11/dataset.zip && \
              unzip /tmp/content/Food-11/dataset.zip -d /tmp/content/Food-11 && \
              echo 'Dataset downloaded and unzipped. Files included:' && \
              ls -la /tmp/content/Food-11;
            "
          fi

      - name: Install Dependencies
        run: |
          docker exec training_container pip install -r workspace/src/image-classification-continuous-x/requirements.txt

      - name: Organize Data
        run: |
          if docker exec training_container bash -c "[ -d '/tmp/content/Food-11/training/class_00' ]"; then
            echo "Dataset is already organized. Skipping organization step."
          else
            echo "Dataset is not organized. Organizing now..."
            docker exec training_container python workspace/src/image-classification-continuous-x/organize_data.py
          fi

      - name: Run Training Script
        run: |
          docker exec training_container python workspace/src/image-classification-continuous-x/model_train.py
        env:
          STORAGE_PATH: /home/cc/models

      - name: Set Accuracy as Environment Variable
        run: |
          EVALUATION_ACCURACY=$(docker exec training_container cat /tmp/temp_models/evaluation_metrics.txt | grep "evaluation_accuracy" | cut -d' ' -f2)
          EVALUATION_LOSS=$(docker exec training_container cat /tmp/temp_models/evaluation_metrics.txt | grep "evaluation_loss" | cut -d' ' -f2)
          echo "Extracted evaluation_accuracy: $EVALUATION_ACCURACY"
          echo "Extracted evaluation_loss: $EVALUATION_LOSS"
          echo "ACCURACY=$EVALUATION_ACCURACY" >> $GITHUB_ENV
          echo "LOSS=$EVALUATION_LOSS" >> $GITHUB_ENV

      # TO DO: move this to evaluate if deploy=true -> potentially only rsync the model that was evaluated instead of all modelstore
      - name: Rsync model store from GPU to Node-0
        run: |
          docker run --rm -v saved_models:/volume -v /tmp:/backup busybox tar czf /backup/volume_backup.tar.gz -C /volume .
          rsync -avz -e ssh /tmp/volume_backup.tar.gz cc@129.114.25.151:/tmp/

      - name: Stop Container
        run: |
          docker stop training_container

  evaluate:
    runs-on: gpu-p100
    needs: train
    if: success()
    steps:
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Start Container
        run: |
          docker run -d --rm --name eval_container \
          -v food11_data:/tmp/content/Food-11 \
          -v saved_models:/tmp/temp_models \
          -v model-to-deploy:/tmp/model_to_deploy \
          -w /workspace \
          tensorflow/tensorflow:latest-gpu tail -f /dev/null

          docker exec eval_container bash -c "
          apt-get update && apt-get install -y git;
          if [ -d 'workspace/src/image-classification-continuous-x' ]; then
            echo 'Repository already exists. Updating...';
            cd /workspace/image-classification-continuous-x && git pull origin main;
          else
            echo 'Cloning repository...';
            git clone https://github.com/tin2294/image-classification-continuous-x.git workspace/src/image-classification-continuous-x;
          fi
          "

      - name: Install Dependencies
        run: |
          docker exec eval_container pip install -r workspace/src/image-classification-continuous-x/requirements.txt

      - name: Extract last model
        run: |
          docker exec eval_container bash -c '
          cd /tmp/temp_models/operatorai-model-store/image-classification/
          latest_dir=$(find "$(ls -d 2024* | grep -v "^versions$" | sort -r | head -n 1)" -type d -print | sort | tail -n 1)
          echo "Latest directory: $latest_dir"
          cd "$latest_dir"
          rm -rf /tmp/model_to_deploy/*
          mkdir -p /tmp/model_to_deploy
          tar -xzf artifacts.tar.gz -C /tmp/model_to_deploy
          '

      - name: Run evaluate script
        run: |
          docker exec eval_container python workspace/src/image-classification-continuous-x/evaluate_model.py

      - name: Stop container
        run: |
          docker stop eval_container

  redeploy:
    runs-on: node-0
    needs: evaluate
    # TO DO: change to deploy if deploy=true
    if: success()
    steps:
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install Modelstore
        run: |
          pip install modelstore

      - name: Extract model store
        run: |
          cd /tmp
          tar -xzf volume_backup.tar.gz -C ~/extracted

      - name: Extract last model
        run: |
          cd ~/extracted/operatorai-model-store/image-classification/
          latest_dir=$(find "$(ls -d 2024* | grep -v '^versions$' | sort -r | head -n 1)" -type d -print | sort | tail -n 1)
          echo "Latest directory: $latest_dir"
          cd "$latest_dir"
          rm -rf ~/model-to-deploy/*
          tar -xzf artifacts.tar.gz -C ~/model-to-deploy

      - name: Copy model to ml-app directory (/home/cc/k8s-ml/app/model.keras)
        run: |
          ls -ld /home/cc/k8s-ml/app/
          cp ~/model-to-deploy/*.keras ~/k8s-ml/app/model.keras

      - name: Build and push Docker image
        run: |
          # Calculate new version based on the current image version
          current_version=$(kubectl get deployment ml-kube-app -o=jsonpath='{.spec.template.spec.containers[?(@.name=="ml-kube-app")].image}' | awk -F: '{print $NF}')
          new_version=$(echo $current_version | awk -F. '{printf "%d.%d.%d", $1, $2, $3+1}')
          echo "Building and pushing image for version: $new_version"
          docker build --network host --no-cache -t node-0:5000/ml-app:$new_version /home/cc/k8s-ml/app
          docker push node-0:5000/ml-app:$new_version

      - name: Cleanup unused Docker resources
        run: |
          set -e
          docker system prune -f || echo "Docker cleanup failed"

      - name: Set new docker image with the last model
        run: |
          current_version=$(kubectl get deployment ml-kube-app -o=jsonpath='{.spec.template.spec.containers[?(@.name=="ml-kube-app")].image}' | awk -F: '{print $NF}')
          new_version=$(echo $current_version | awk -F. '{printf "%d.%d.%d", $1, $2, $3+1}')
          echo "Setting image for version: $new_version"
          kubectl set image deployment ml-kube-app ml-kube-app=node-0:5000/ml-app:$new_version

      - name: Wait for deployment to complete
        run: |
          kubectl rollout status deployment ml-kube-app

      - name: Display Docker Logs
        run: |
          docker logs $(docker ps -q -f ancestor=node-0:5000/ml-app:$new_version) || echo "No Docker container running for ml-app"

      - name: Display Kubernetes Pod Status
        run: |
          kubectl get pods -o wide || echo "Kubernetes pod status not available"

      - name: Display Kubernetes URL
        run: |
          echo http://$(curl -s ifconfig.me/ip):32000
